# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MylfnHCtZHh8PQuSptD7Q5Zyoj_fPp5d
"""

import pandas as pd
import numpy as np

crop = pd.read_csv('Crop_recommendation.csv')

crop.head()

crop.shape

crop.info()

crop.isnull().sum()

crop.duplicated().sum()

crop.describe()

crop_corr = crop.drop('label', axis=1).corr()

import seaborn as sns
import matplotlib.pyplot as plt

sns.heatmap(crop_corr, annot=True, cbar=True, cmap='Blues')

crop.label.value_counts()

crop['label'].unique()

sns.distplot(crop['P'])
plt.show()

sns.histplot(crop['N'])
plt.show()

crop_dict = {
    'rice':1,
    'maize':2,
    'chickpea':3,
    'kidneybeans':4,
    'pigeonpeas':5,
    'mothbeans':6,
    'mungbean':7,
    'blackgram':8,
    'lentil':9,
    'pomegranate':10,
    'banana':11,
    'mango':12,
    'grapes':13,
    'watermelon':14,
    'muskmelon':15,
    'apple':16,
    'orange':17,
    'papaya':18,
    'coconut':19,
    'cotton':20,
    'jute':21,
    'coffee':22
}

crop['label'] = crop['label'].map(crop_dict)

crop.head()

crop.label.unique()

X = crop.drop('label', axis=1)
y= crop['label']

X.head()

y.head()

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)

X_train.shape

from sklearn.preprocessing import MinMaxScaler
mx= MinMaxScaler()
X_train = mx.fit_transform(X_train)
X_test = mx.fit_transform(X_test)

X_train

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
sc.fit(X_train)
X_train = sc.transform(X_train)
X_test = sc.transform(X_test)

from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier
from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

models = {
    'LogisticRegression': LogisticRegression(),
    'GaussianNB': GaussianNB(),
    'KNeighborsClassifier': KNeighborsClassifier(),
    'DecisionTreeClassifier': DecisionTreeClassifier(),
    'ExtraTreeClassifier': ExtraTreeClassifier(),
    'RandomForestClassifier': RandomForestClassifier(),
    'BaggingClassifier': BaggingClassifier(),
    'AdaBoostClassifier': AdaBoostClassifier(),
    'GradientBoostingClassifier': GradientBoostingClassifier(),
    'SVC': SVC()
}

for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    score = accuracy_score(y_test, y_pred)
    print(f'Accuracy score of {name} is {accuracy_score(y_test, y_pred)}')

rf = RandomForestClassifier()
rf.fit(X_train,y_train)
y_pred = rf.predict(X_test)
accuracy_score(y_test, y_pred)

crop.columns

def recommendation(N, P, K, temperature, humidity, ph, rainfall):
    features = np.array([[N, P, K, temperature, humidity, ph, rainfall]])
    mx_features = mx.transform(features)
    sc_mx_features = sc.transform(mx_features)
    prediction = rf.predict(sc_mx_features).reshape(1,1)
    return prediction[0]

crop.head()

N=90
P=42
K=43
tempreture=20.879744
humidity=82.002744
ph=6.502985
rainfall=202.935536

predict = recommendation(N, P, K, tempreture, humidity, ph, rainfall)
print(predict)

import pickle
pickle.dump(rf, open('model.pkl', 'wb'))
pickle.dump(mx, open('minmaxscaler.pkl', 'wb'))
pickle.dump(sc, open('standardscaler.pkl', 'wb'))

